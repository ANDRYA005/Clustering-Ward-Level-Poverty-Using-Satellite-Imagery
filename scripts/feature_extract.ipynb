{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the images marked as valid per cluster, we pass them through the CNN and extract their feature vectors. the results are stored at a per-country basis. For example, all Malawi feature extractions will go into results/malawi_2016/cnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '..'\n",
    "# COUNTRIES_DIR = os.path.join(BASE_DIR, 'data', 'countries')\n",
    "# PROCESSED_DIR = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "# RESULTS_DIR = os.path.join(BASE_DIR, 'results')\n",
    "CNN_IMAGE_DIR = os.path.join(BASE_DIR, 'images')\n",
    "CNN_DIR = os.path.join(BASE_DIR, 'models', 'trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "# for country in ['malawi_2016', 'ethiopia_2015', 'nigeria_2015']:\n",
    "#     os.makedirs(os.path.join(RESULTS_DIR, country), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extract with CNN\n",
    "If you have run this step before, you can skip it and run the commented out code in the next section to quick-start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_images = pd.read_csv(os.path.join(PROCESSED_DIR, 'image_download_actual.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_lat</th>\n",
       "      <th>image_lon</th>\n",
       "      <th>cluster_lat</th>\n",
       "      <th>cluster_lon</th>\n",
       "      <th>cons_pc</th>\n",
       "      <th>nightlights</th>\n",
       "      <th>country</th>\n",
       "      <th>nightlights_bin</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17.09515_35.17229723579403_-17.09515_35.21721...</td>\n",
       "      <td>-17.095150</td>\n",
       "      <td>35.172297</td>\n",
       "      <td>-17.09515</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.08017807859801_35.17229723579403_-17.09515...</td>\n",
       "      <td>-17.080178</td>\n",
       "      <td>35.172297</td>\n",
       "      <td>-17.09515</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-17.125093842803985_35.18726915719602_-17.0951...</td>\n",
       "      <td>-17.125094</td>\n",
       "      <td>35.187269</td>\n",
       "      <td>-17.09515</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-17.140065764205975_35.20224107859801_-17.0951...</td>\n",
       "      <td>-17.140066</td>\n",
       "      <td>35.202241</td>\n",
       "      <td>-17.09515</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.065206157196016_35.20224107859801_-17.0951...</td>\n",
       "      <td>-17.065206</td>\n",
       "      <td>35.202241</td>\n",
       "      <td>-17.09515</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  image_lat  image_lon  \\\n",
       "0  -17.09515_35.17229723579403_-17.09515_35.21721... -17.095150  35.172297   \n",
       "1  -17.08017807859801_35.17229723579403_-17.09515... -17.080178  35.172297   \n",
       "2  -17.125093842803985_35.18726915719602_-17.0951... -17.125094  35.187269   \n",
       "3  -17.140065764205975_35.20224107859801_-17.0951... -17.140066  35.202241   \n",
       "4  -17.065206157196016_35.20224107859801_-17.0951... -17.065206  35.202241   \n",
       "\n",
       "   cluster_lat  cluster_lon   cons_pc  nightlights country  nightlights_bin  \\\n",
       "0    -17.09515    35.217213  1.423239     0.025206      mw                0   \n",
       "1    -17.09515    35.217213  1.423239     0.025206      mw                0   \n",
       "2    -17.09515    35.217213  1.423239     0.025206      mw                0   \n",
       "3    -17.09515    35.217213  1.423239     0.025206      mw                0   \n",
       "4    -17.09515    35.217213  1.423239     0.025206      mw                0   \n",
       "\n",
       "   is_train  \n",
       "0      True  \n",
       "1      True  \n",
       "2     False  \n",
       "3      True  \n",
       "4      True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu as backend\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} as backend')\n",
    "model = torch.load(CNN_DIR, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rip off the final layers\n",
    "model.classifier = model.classifier[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836e559c8a46435b903f426fc89a0cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7783,  1.1016, -0.1959,  ...,  0.0427,  0.0952, -1.1975],\n",
      "        [-0.7034,  0.1166, -0.1621,  ...,  0.1045,  1.0096, -0.9460],\n",
      "        [-1.3177, -0.0722, -0.3931,  ...,  0.0484,  0.1903, -1.2159],\n",
      "        ...,\n",
      "        [-0.0515, -0.4898,  0.3363,  ...,  0.1145,  0.0422, -0.6688],\n",
      "        [-0.1311, -0.1404,  0.0806,  ...,  0.6589, -0.0551, -1.0909],\n",
      "        [-1.2350,  0.0265,  0.2964,  ...,  0.4178,  0.9953, -1.6981]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5550, -0.2291,  0.3078,  ..., -0.0287,  0.4799, -2.0992],\n",
      "        [-1.6506, -0.1278,  0.3161,  ...,  0.3962, -0.3737, -1.4776],\n",
      "        [-2.0778, -0.4005,  0.0263,  ...,  1.0800,  0.0548, -1.8931],\n",
      "        ...,\n",
      "        [-0.7049, -0.6875,  0.8751,  ..., -0.6134,  0.4951, -0.3611],\n",
      "        [-1.2870, -0.6103,  0.7389,  ...,  0.2399,  0.6828, -1.1949],\n",
      "        [-1.5025, -0.2589, -0.0039,  ...,  0.4699,  0.6253, -1.6142]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.4995, -0.1818,  0.0358,  ...,  0.2018,  0.4279, -1.3771],\n",
      "        [-1.3361, -0.0203,  0.1738,  ...,  0.3838,  0.3251, -1.0701],\n",
      "        [-0.7435, -0.4276,  0.7117,  ..., -0.3294,  0.5569, -0.5744],\n",
      "        ...,\n",
      "        [-0.4580, -0.4715,  0.6755,  ..., -0.2469,  0.5763, -0.6529],\n",
      "        [-0.3054, -0.2252,  0.0468,  ...,  0.0647,  0.4045, -0.7146],\n",
      "        [-0.3671, -0.4280,  0.4689,  ..., -0.2984,  0.3930, -0.3716]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "# custom dataset for fast image loading and processing\n",
    "# does not follow the usual style of folder -> folder for each class -> image\n",
    "# we just want one folder with images\n",
    "class ForwardPassDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dir, transformer):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_list = os.listdir(self.image_dir)\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_list[index]\n",
    "\n",
    "        # Load image\n",
    "        X = self.filename_to_im_tensor(self.image_dir + '/' + image_name)\n",
    "        \n",
    "        # dataloaders need to return a label, but for the forward pass we don't really care\n",
    "        return X, -1\n",
    "    \n",
    "    def filename_to_im_tensor(self, file):\n",
    "        im = plt.imread(file)[:,:,:3]\n",
    "        im = self.transformer(im)\n",
    "        return im\n",
    "\n",
    "model.eval()  \n",
    "classes = [0, 1, 2]\n",
    "# shape of final array will be (num_validation_images, 4096)\n",
    "# we also want to record the image each index represents\n",
    "feats = np.zeros((1000, 4096))\n",
    "image_order = []\n",
    "i = 0\n",
    "# for c in classes:\n",
    "    # use the validation images to do the forward pass\n",
    "dataset = ForwardPassDataset(os.path.join(CNN_IMAGE_DIR, 'ward_1', 'edited'), transformer)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "image_order += dataset.image_list\n",
    "# forward pass for this class\n",
    "for inputs, _ in tqdm(dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model(inputs)\n",
    "    print(outputs)\n",
    "#     feats[i:i+len(inputs),:] = outputs.cpu().detach().numpy()\n",
    "#     i += len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00.png',\n",
       " '01.png',\n",
       " '02.png',\n",
       " '03.png',\n",
       " '04.png',\n",
       " '05.png',\n",
       " '10.png',\n",
       " '11.png',\n",
       " '12.png',\n",
       " '13.png',\n",
       " '14.png',\n",
       " '15.png',\n",
       " '20.png',\n",
       " '21.png',\n",
       " '22.png',\n",
       " '23.png',\n",
       " '24.png',\n",
       " '25.png',\n",
       " '30.png',\n",
       " '31.png',\n",
       " '32.png',\n",
       " '33.png',\n",
       " '34.png',\n",
       " '35.png']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>feat_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.513181862198008_39.768191057994024_10.52815...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-14.632534157196016_34.981995235794024_-14.662...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-14.526346764205977_35.593520078598004_-14.481...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.4290196173360155_7.26950147266_7.45896346014...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.405547698244352_34.14279535535209_-10.4038...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  feat_index\n",
       "0  10.513181862198008_39.768191057994024_10.52815...           0\n",
       "1  -14.632534157196016_34.981995235794024_-14.662...           1\n",
       "2  -14.526346764205977_35.593520078598004_-14.481...           2\n",
       "3  7.4290196173360155_7.26950147266_7.45896346014...           3\n",
       "4  -10.405547698244352_34.14279535535209_-10.4038...           4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass_df = pd.DataFrame.from_dict({'image_name': image_order, 'feat_index': np.arange(len(image_order))})\n",
    "forward_pass_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consumption = pd.merge(left=df_images, right=forward_pass_df, on='image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have we maintained all validation images?\n",
    "assert len(df_consumption) == (~df_images['is_train']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_lat</th>\n",
       "      <th>image_lon</th>\n",
       "      <th>cluster_lat</th>\n",
       "      <th>cluster_lon</th>\n",
       "      <th>cons_pc</th>\n",
       "      <th>nightlights</th>\n",
       "      <th>country</th>\n",
       "      <th>nightlights_bin</th>\n",
       "      <th>is_train</th>\n",
       "      <th>feat_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17.125093842803985_35.18726915719602_-17.0951...</td>\n",
       "      <td>-17.125094</td>\n",
       "      <td>35.187269</td>\n",
       "      <td>-17.095150</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.140065764205975_35.232184921401995_-17.095...</td>\n",
       "      <td>-17.140066</td>\n",
       "      <td>35.232185</td>\n",
       "      <td>-17.095150</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-17.065206157196016_35.262128764205976_-17.095...</td>\n",
       "      <td>-17.065206</td>\n",
       "      <td>35.262129</td>\n",
       "      <td>-17.095150</td>\n",
       "      <td>35.217213</td>\n",
       "      <td>1.423239</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-17.07737907859801_35.069727235794026_-17.0923...</td>\n",
       "      <td>-17.077379</td>\n",
       "      <td>35.069727</td>\n",
       "      <td>-17.092351</td>\n",
       "      <td>35.114643</td>\n",
       "      <td>1.266204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.137266764205975_35.08469915719602_-17.0923...</td>\n",
       "      <td>-17.137267</td>\n",
       "      <td>35.084699</td>\n",
       "      <td>-17.092351</td>\n",
       "      <td>35.114643</td>\n",
       "      <td>1.266204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>mw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  image_lat  image_lon  \\\n",
       "0  -17.125093842803985_35.18726915719602_-17.0951... -17.125094  35.187269   \n",
       "1  -17.140065764205975_35.232184921401995_-17.095... -17.140066  35.232185   \n",
       "2  -17.065206157196016_35.262128764205976_-17.095... -17.065206  35.262129   \n",
       "3  -17.07737907859801_35.069727235794026_-17.0923... -17.077379  35.069727   \n",
       "4  -17.137266764205975_35.08469915719602_-17.0923... -17.137267  35.084699   \n",
       "\n",
       "   cluster_lat  cluster_lon   cons_pc  nightlights country  nightlights_bin  \\\n",
       "0   -17.095150    35.217213  1.423239     0.025206      mw                0   \n",
       "1   -17.095150    35.217213  1.423239     0.025206      mw                0   \n",
       "2   -17.095150    35.217213  1.423239     0.025206      mw                0   \n",
       "3   -17.092351    35.114643  1.266204     0.000000      mw                0   \n",
       "4   -17.092351    35.114643  1.266204     0.000000      mw                0   \n",
       "\n",
       "   is_train  feat_index  \n",
       "0     False         318  \n",
       "1     False        1861  \n",
       "2     False         836  \n",
       "3     False          18  \n",
       "4     False        1051  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consumption.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Features\n",
    "For each country, we aggregate the image features per cluster and save them to results/country/cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_abbrv = ['mw', 'eth', 'ng']\n",
    "country_dir = ['malawi_2016', 'ethiopia_2015', 'nigeria_2015']\n",
    "\n",
    "for ca, cd in zip(country_abbrv, country_dir):\n",
    "    df_c = df_consumption[df_consumption['country'] == ca]\n",
    "    group = df_c.groupby(['cluster_lat', 'cluster_lon'])\n",
    "    x = np.zeros((len(group), 4096))\n",
    "    cluster_list = [] # the corresponding clusters (lat, lon) to the x aggregate feature array\n",
    "    for i, g in enumerate(group):\n",
    "        lat, lon = g[0]\n",
    "        im_sub = df_consumption[(df_consumption['cluster_lat'] == lat) & (df_consumption['cluster_lon'] == lon)].reset_index(drop=True)\n",
    "        agg_feats = np.zeros((len(im_sub), 4096))\n",
    "        for j, d in im_sub.iterrows():\n",
    "            agg_feats[j,:] = feats[d.feat_index]\n",
    "        agg_feats = agg_feats.mean(axis=0) # averages the features across all images in the cluster\n",
    "\n",
    "        x[i,:] = agg_feats\n",
    "        cluster_list.append([lat, lon])\n",
    "    # save to the correct directory\n",
    "    save_dir = os.path.join(RESULTS_DIR, cd, 'cnn')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    np.save(os.path.join(save_dir, 'cluster_feats.npy'), x)\n",
    "    pickle.dump(cluster_list, open(os.path.join(save_dir, 'cluster_order.pkl'), 'wb')) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "honoursprojectenv",
   "language": "python",
   "name": "honoursprojectenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
